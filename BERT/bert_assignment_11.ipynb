{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jftnoqayyCPR",
        "outputId": "55619685-d3c6-4548-a57b-025a713b61be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EVA 8 code"
      ],
      "metadata": {
        "id": "wDr60PMANGPc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "chLl-BYWiatz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624,
          "referenced_widgets": [
            "438fd45654d2411387c4fac2a79043ba",
            "b348965177324a4d917d26dc85e7cf9a",
            "f66eff5d14d2497fa57975782bb3df1d",
            "f1c3be14649b49b792d86cbb5352311e",
            "d064cfcbf916409c8b9e1801fa0192b2",
            "b6ae5681f7f94e249749e1453509aa15",
            "f261d7f18d034d6195beee16cac8c070",
            "a73a27a57ad24c8f9fd9235ef871e96e",
            "bbeb8c9114c44dc5b29b59cd7ab71082",
            "7b9b9780b6344296a49a2ebd2165f667",
            "350bb42b3a634a8da41999c08e8306ef"
          ]
        },
        "outputId": "f966fb27-38d1-4ff4-9c1d-aeddcc1c66ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.11.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb (/root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "438fd45654d2411387c4fac2a79043ba"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "imdb_dataset = load_dataset('imdb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "60b9yT4Yie59"
      },
      "outputs": [],
      "source": [
        "# imbd = pd.DataFrame.from_dict(imdb_dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yab8uGJtin6r"
      },
      "outputs": [],
      "source": [
        "# imbd = imbd.drop(columns=['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-m2byjyAjFaJ"
      },
      "outputs": [],
      "source": [
        "# imbd.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RDmz9VGfNJJp"
      },
      "outputs": [],
      "source": [
        "# wikitext_dataset = load_dataset('wikitext', 'wikitext-103-raw-v1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KY5csG3fNJMD"
      },
      "outputs": [],
      "source": [
        "# wikitext_dataset['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8xXgnlWeNJN4"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# wikitext_data = pd.DataFrame.from_dict(wikitext_dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fpL0oKlvNJbk"
      },
      "outputs": [],
      "source": [
        "# wikitext_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WVixWXKCNJdR"
      },
      "outputs": [],
      "source": [
        "# snli_dataset = load_dataset('snli')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aB4xrDimNJny"
      },
      "outputs": [],
      "source": [
        "# snli_dataset['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YhLosvp0NJrj"
      },
      "outputs": [],
      "source": [
        "#  snli_data= pd.DataFrame.from_dict(snli_dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kJmNbOw4NJum"
      },
      "outputs": [],
      "source": [
        "# snli_data = snli_data.drop(columns=['premise','label'])\n",
        "# snli_data = snli_data.rename(columns={'hypothesis': 'text'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eSFfys3MNJyA"
      },
      "outputs": [],
      "source": [
        "# snli_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ReH5U4LiNJ68"
      },
      "outputs": [],
      "source": [
        "# cola_dataset = load_dataset('glue', 'cola')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "I8mheyrsNKDq"
      },
      "outputs": [],
      "source": [
        "# cola_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QpXlqbGSNKLc"
      },
      "outputs": [],
      "source": [
        "# cola_dataset['train']['sentence']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Zp0YljsTNKTx"
      },
      "outputs": [],
      "source": [
        "# cola_data= pd.DataFrame.from_dict(cola_dataset['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0fOTR4vxNKXG"
      },
      "outputs": [],
      "source": [
        "# cola_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OFfsT1vVNKZO"
      },
      "outputs": [],
      "source": [
        "# cola_data = cola_data.drop(columns=['idx','label'])\n",
        "# cola_data = cola_data.rename(columns={'sentence': 'text'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Xh6cHsZPc0_s"
      },
      "outputs": [],
      "source": [
        "# cola_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zy-bspHjSYf9"
      },
      "outputs": [],
      "source": [
        "# merged_df = pd.concat([imbd, wikitext_data, snli_data, cola_data], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DTHIbGMMUzLk"
      },
      "outputs": [],
      "source": [
        "# merged_df = merged_df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YkTRR88xx9s",
        "outputId": "42a676df-b639-4ebf-896b-42726d23c9c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/sunandini\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/sunandini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "r63Sd49xx_4-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4O0TXwrwX0RL"
      },
      "outputs": [],
      "source": [
        "# merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Dhk837oMX3O-"
      },
      "outputs": [],
      "source": [
        "# merged_df.to_csv('data.txt', sep='\\t', header=False, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwhAKREc1fBp"
      },
      "source": [
        "## BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "G9Fx2TO11jU5"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# Libs\n",
        "# =============================================================================\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "from os.path import exists\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import re\n",
        "\n",
        "\n",
        "# ==========================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZDbdkTU31kue"
      },
      "outputs": [],
      "source": [
        "# Transformer\n",
        "# =============================================================================\n",
        "def attention(q, k, v, mask = None, dropout = None):\n",
        "    scores = q.matmul(k.transpose(-2, -1))\n",
        "    scores /= math.sqrt(q.shape[-1])\n",
        "    \n",
        "    #mask\n",
        "    scores = scores if mask is None else scores.masked_fill(mask == 0, -1e3)\n",
        "    \n",
        "    scores = F.softmax(scores, dim = -1)\n",
        "    scores = dropout(scores) if dropout is not None else scores\n",
        "    output = scores.matmul(v)\n",
        "    return output\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, n_heads, out_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        \n",
        "#        self.q_linear = nn.Linear(out_dim, out_dim)\n",
        "#        self.k_linear = nn.Linear(out_dim, out_dim)\n",
        "#        self.v_linear = nn.Linear(out_dim, out_dim)\n",
        "        self.linear = nn.Linear(out_dim, out_dim*3)\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "        self.out_dim = out_dim\n",
        "        self.out_dim_per_head = out_dim // n_heads\n",
        "        self.out = nn.Linear(out_dim, out_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def split_heads(self, t):\n",
        "        return t.reshape(t.shape[0], -1, self.n_heads, self.out_dim_per_head)\n",
        "    \n",
        "    def forward(self, x, y=None, mask=None):\n",
        "        #in decoder, y comes from encoder. In encoder, y=x\n",
        "        y = x if y is None else y\n",
        "        \n",
        "        qkv = self.linear(x) # BS * SEQ_LEN * (3*EMBED_SIZE_L)\n",
        "        q = qkv[:, :, :self.out_dim] # BS * SEQ_LEN * EMBED_SIZE_L\n",
        "        k = qkv[:, :, self.out_dim:self.out_dim*2] # BS * SEQ_LEN * EMBED_SIZE_L\n",
        "        v = qkv[:, :, self.out_dim*2:] # BS * SEQ_LEN * EMBED_SIZE_L\n",
        "        \n",
        "        #break into n_heads\n",
        "        q, k, v = [self.split_heads(t) for t in (q,k,v)]  # BS * SEQ_LEN * HEAD * EMBED_SIZE_P_HEAD\n",
        "        q, k, v = [t.transpose(1,2) for t in (q,k,v)]  # BS * HEAD * SEQ_LEN * EMBED_SIZE_P_HEAD\n",
        "        \n",
        "        #n_heads => attention => merge the heads => mix information\n",
        "        scores = attention(q, k, v, mask, self.dropout) # BS * HEAD * SEQ_LEN * EMBED_SIZE_P_HEAD\n",
        "        scores = scores.transpose(1,2).contiguous().view(scores.shape[0], -1, self.out_dim) # BS * SEQ_LEN * EMBED_SIZE_L\n",
        "        out = self.out(scores)  # BS * SEQ_LEN * EMBED_SIZE\n",
        "        \n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, inp_dim, inner_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(inp_dim, inner_dim)\n",
        "        self.linear2 = nn.Linear(inner_dim, inp_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #inp => inner => relu => dropout => inner => inp\n",
        "        return self.linear2(self.dropout(F.relu(self.linear1(x)))) \n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, n_heads, inner_transformer_size, inner_ff_size, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.mha = MultiHeadAttention(n_heads, inner_transformer_size, dropout)\n",
        "        self.ff = FeedForward(inner_transformer_size, inner_ff_size, dropout)\n",
        "        self.norm1 = nn.LayerNorm(inner_transformer_size)\n",
        "        self.norm2 = nn.LayerNorm(inner_transformer_size)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, x, mask=None):\n",
        "        x2 = self.norm1(x)\n",
        "        x = x + self.dropout1(self.mha(x2, mask=mask))\n",
        "        x2 = self.norm2(x)\n",
        "        x = x + self.dropout2(self.ff(x2))\n",
        "        return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, n_code, n_heads, embed_size, inner_ff_size, n_embeddings, seq_len, dropout=.1):\n",
        "        super().__init__()\n",
        "        \n",
        "        #model input\n",
        "        self.embeddings = nn.Embedding(n_embeddings, embed_size)\n",
        "        self.pe = PositionalEmbedding(embed_size, seq_len)\n",
        "        \n",
        "        #backbone\n",
        "        encoders = []\n",
        "        for i in range(n_code):\n",
        "            encoders += [EncoderLayer(n_heads, embed_size, inner_ff_size, dropout)]\n",
        "        self.encoders = nn.ModuleList(encoders)\n",
        "        \n",
        "        #language model\n",
        "        self.norm = nn.LayerNorm(embed_size)\n",
        "        self.linear = nn.Linear(embed_size, n_embeddings, bias=False)\n",
        "                \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "        x = x + self.pe(x)\n",
        "        for encoder in self.encoders:\n",
        "            x = encoder(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "# Positional Embedding\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_len = 80):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "        pe.requires_grad = False\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.pe[:,:x.size(1)] #x.size(1) = seq_len"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class SentencesDataset(Dataset):\n",
        "#     #Init dataset\n",
        "#     def __init__(self, sentences, vocab, seq_len):\n",
        "#         dataset = self\n",
        "        \n",
        "#         dataset.sentences = sentences\n",
        "#         dataset.vocab = vocab + ['<ignore>', '<oov>', '<mask>',\"<random>\"]\n",
        "#         dataset.vocab = {e:i for i, e in enumerate(dataset.vocab)} \n",
        "#         dataset.rvocab = {v:k for k,v in dataset.vocab.items()}\n",
        "#         dataset.seq_len = seq_len\n",
        "        \n",
        "#         #special tags\n",
        "#         dataset.IGNORE_IDX = dataset.vocab['<ignore>'] #replacement tag for tokens to ignore\n",
        "#         dataset.OUT_OF_VOCAB_IDX = dataset.vocab['<oov>'] #replacement tag for unknown words\n",
        "#         dataset.MASK_IDX = dataset.vocab['<mask>'] #replacement tag for the masked word prediction task\n",
        "#         dataset.RANDOM_IDX = dataset.vocab['<random>']#replacement tag for the masked word prediction task\n",
        "    \n",
        "    \n",
        "#     #fetch data\n",
        "#     def __getitem__(self, index, p_random_mask=0.15):\n",
        "#         dataset = self\n",
        "        \n",
        "#         #while we don't have enough word to fill the sentence for a batch\n",
        "#         s = []\n",
        "#         while len(s) < dataset.seq_len:\n",
        "#             s.extend(dataset.get_sentence_idx(index % len(dataset)))\n",
        "#             index += 1\n",
        "        \n",
        "#         #ensure that the sequence is of length seq_len\n",
        "#         s = s[:dataset.seq_len]\n",
        "#         [s.append(dataset.IGNORE_IDX) for i in range(dataset.seq_len - len(s))] #PAD ok\n",
        "        \n",
        "#         #swap words with random words\n",
        "#         s = [(random.choice(s) if random.random() < p_random_mask else w, w) for w in s]\n",
        "        \n",
        "#         #replace some words with RANDOM_IDX\n",
        "#         s = [(dataset.RANDOM_IDX, w) if random.random() < p_random_mask else (w, dataset.IGNORE_IDX) for w in s]\n",
        "        \n",
        "#         return {'input': torch.Tensor([w[0] for w in s]).long(),\n",
        "#                 'target': torch.Tensor([w[1] if w[0] != dataset.RANDOM_IDX else dataset.RANDOM_IDX for w in s]).long()}\n",
        "\n",
        "#     #return length\n",
        "#     def __len__(self):\n",
        "#         return len(self.sentences)\n",
        "\n",
        "#     #get words id\n",
        "#     def get_sentence_idx(self, index):\n",
        "#         dataset = self\n",
        "#         s = dataset.sentences[index]\n",
        "#         s = [dataset.vocab[w] if w in dataset.vocab else dataset.OUT_OF_VOCAB_IDX for w in s] \n",
        "#         return s\n"
      ],
      "metadata": {
        "id": "IWXnoArilZXg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "class SentencesDataset(Dataset):\n",
        "    #Init dataset\n",
        "    def __init__(self, sentences, vocab, seq_len):\n",
        "        dataset = self\n",
        "        \n",
        "        dataset.sentences = sentences\n",
        "        dataset.vocab = vocab + ['<ignore>', '<oov>', '<mask>',\"<random>\"]\n",
        "        dataset.vocab = {e:i for i, e in enumerate(dataset.vocab)} \n",
        "        dataset.rvocab = {v:k for k,v in dataset.vocab.items()}\n",
        "        dataset.seq_len = seq_len\n",
        "        \n",
        "        #special tags\n",
        "        dataset.IGNORE_IDX = dataset.vocab['<ignore>'] #replacement tag for tokens to ignore\n",
        "        dataset.OUT_OF_VOCAB_IDX = dataset.vocab['<oov>'] #replacement tag for unknown words\n",
        "        dataset.MASK_IDX = dataset.vocab['<mask>'] #replacement tag for the masked word prediction task\n",
        "        dataset.RANDOM_IDX = dataset.vocab['<random>']#replacement tag for the masked word prediction task\n",
        "    \n",
        "    \n",
        "    #fetch data\n",
        "    #fetch data\n",
        "    def __getitem__(self, index, p_random_mask=0.15):\n",
        "        dataset = self\n",
        "        \n",
        "        #while we don't have enough word to fill the sentence for a batch\n",
        "        s = []\n",
        "        while len(s) < dataset.seq_len:\n",
        "            s.extend(dataset.get_sentence_idx(index % len(dataset)))\n",
        "            index += 1\n",
        "        \n",
        "        #ensure that the sequence is of length seq_len\n",
        "        s = s[:dataset.seq_len]\n",
        "        [s.append(dataset.IGNORE_IDX) for i in range(dataset.seq_len - len(s))] #PAD ok\n",
        "        \n",
        "       #swap words with random words\n",
        "        s = [(random.choice(s) if random.random() < p_random_mask else w, w) for w in s]\n",
        "\n",
        "        \n",
        "        #replace some words with RANDOM_IDX\n",
        "        s = [(dataset.RANDOM_IDX, w[1]) if random.random() < p_random_mask else (w[0], dataset.IGNORE_IDX) for w in s]\n",
        "        \n",
        "        return {'input': torch.Tensor([w[0] for w in s]).long(),\n",
        "                'target': torch.Tensor([w[1] if w[0] != dataset.RANDOM_IDX else dataset.RANDOM_IDX for w in s]).long()}\n",
        "\n",
        "\n",
        "    #return length\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    #get words id\n",
        "    def get_sentence_idx(self, index):\n",
        "        dataset = self\n",
        "        s = dataset.sentences[index]\n",
        "        s = [dataset.vocab[w] if w in dataset.vocab else dataset.OUT_OF_VOCAB_IDX for w in s] \n",
        "        return s"
      ],
      "metadata": {
        "id": "BtFdAAmPiThq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"sentences      ...\",sentences[1:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTR9hRx09edy",
        "outputId": "06834704-d3b1-46ea-d83e-ac27a45ac535"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences      ... ['\"\"\"i am curious: yellow\"\" is a risible and pretentious steaming pile. it doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. as for the claim that frontal male nudity is an automatic nc-17, that isn\\'t true. i\\'ve seen r-rated films with male nudity. granted, they only offer some fleeting views, but where are the r-rated films with gaping vulvas and flapping labia? nowhere, because they don\\'t exist. the same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. and those pretentious indie movies like the brown bunny, in which we\\'re treated to the site of vincent gallo\\'s throbbing johnson, but not a trace of pink visible on chloe sevigny. before crying (or implying) \"\"double-standard\"\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. in fact, you generally won\\'t see female genitals in an american film in anything short of porn or explicit erotica. this alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu3exJ_7z4IU",
        "outputId": "08121926-c599-4db0-c1a7-eaeb7ccfacb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initializing..\n",
            "loading text...\n",
            "tokenizing sentences...\n",
            "creating/loading vocab...\n",
            "creating dataset...\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Methods / Class\n",
        "# =============================================================================\n",
        "def get_batch(loader, loader_iter):\n",
        "    try:\n",
        "        batch = next(loader_iter)\n",
        "    except StopIteration:\n",
        "        loader_iter = iter(loader)\n",
        "        batch = next(loader_iter)\n",
        "    return batch, loader_iter\n",
        "\n",
        "# =============================================================================\n",
        "# #Init\n",
        "# =============================================================================\n",
        "print('initializing..')\n",
        "batch_size = 1024\n",
        "seq_len = 20\n",
        "embed_size = 128\n",
        "inner_ff_size = embed_size * 4\n",
        "n_heads = 8\n",
        "n_code = 8\n",
        "n_vocab = 40000\n",
        "dropout = 0.1\n",
        "# n_workers = 12\n",
        "\n",
        "#optimizer\n",
        "optim_kwargs = {'lr':1e-4, 'weight_decay':1e-4, 'betas':(.9,.999)}\n",
        "\n",
        "# =============================================================================\n",
        "# Input\n",
        "# =============================================================================\n",
        "#1) load text\n",
        "print('loading text...')\n",
        "pth = '/content/drive/MyDrive/data.txt'\n",
        "sentences = open(pth).read().lower().split('\\n')\n",
        "\n",
        "#2) tokenize sentences (can be done during training, you can also use spacy udpipe)\n",
        "print('tokenizing sentences...')\n",
        "special_chars = ',?;.:/*!+-()[]{}\"\\'&'\n",
        "sentences = [re.sub(f'[{re.escape(special_chars)}]', ' \\g<0> ', s).split(' ') for s in sentences]\n",
        "sentences = [[w for w in s if len(w)] for s in sentences]\n",
        "print(\"sentences\",sentences)\n",
        "#3) create vocab if not already created\n",
        "print('creating/loading vocab...')\n",
        "pth = '/content/vocab.txt'\n",
        "if not exists(pth):\n",
        "    words = [w for s in sentences for w in s]\n",
        "    vocab = Counter(words).most_common(n_vocab) #keep the N most frequent words\n",
        "    vocab = [w[0] for w in vocab]\n",
        "    open(pth, 'w+').write('\\n'.join(vocab))\n",
        "else:\n",
        "    vocab = open(pth).read().split('\\n')\n",
        "\n",
        "#4) create dataset\n",
        "print('creating dataset...')\n",
        "\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Split dataset into train and validation\n",
        "\n",
        "\n",
        "dataset = SentencesDataset(sentences, vocab, seq_len)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "# kwargs = {'num_workers':n_workers, 'shuffle':True,  'drop_last':True, 'pin_memory':True, 'batch_size':batch_size}\n",
        "kwargs = {'shuffle':True,  'drop_last':True, 'pin_memory':True, 'batch_size':batch_size}\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders for train and validation\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, **kwargs)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, **kwargs)\n",
        "#data_loader = torch.utils.data.DataLoader(dataset, **kwargs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(iter(dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYehZGk07qm_",
        "outputId": "29e2cefa-798b-4cd5-df75-1f7cb419b3ec"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': tensor([    1,    44,  7523, 40003,  1191,  9352,    13,  1338,  1338,   271,\n",
            "          282, 40003,   142,    19, 40003,     0,  2460,     1,  2714,    19]), 'target': tensor([40000, 40000, 40000, 40003, 40000, 40000, 40000, 40000, 40000, 40000,\n",
            "        40000, 40003, 40000, 40000, 40003, 40000, 40000, 40000, 40000, 40000])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = train_loader"
      ],
      "metadata": {
        "id": "h2YHgDz9u7v7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Nu1c09hU18Ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f30a14-9a75-4846-ce85-0ef8d7e16cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initializing model...\n",
            "initializing optimizer and loss...\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Model\n",
        "# =============================================================================\n",
        "#init model\n",
        "print('initializing model...')\n",
        "model = Transformer(n_code, n_heads, embed_size, inner_ff_size, len(dataset.vocab), seq_len, dropout)\n",
        "model = model.cuda()\n",
        "\n",
        "# =============================================================================\n",
        "# Optimizer\n",
        "# =============================================================================\n",
        "print('initializing optimizer and loss...')\n",
        "optimizer = optim.Adam(model.parameters(), **optim_kwargs)\n",
        "loss_model = nn.CrossEntropyLoss(ignore_index=dataset.IGNORE_IDX)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "A5NVyWRe2E7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641f49c0-cba3-4758-9c67-10c1a44806f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training...\n",
            "it: 0  | loss 11.16  | Δw: 7.708\n",
            "it: 10  | loss 5.64  | Δw: 2.024\n",
            "it: 20  | loss 4.53  | Δw: 0.634\n",
            "it: 30  | loss 4.17  | Δw: 0.302\n",
            "it: 40  | loss 3.9  | Δw: 0.205\n",
            "it: 50  | loss 3.64  | Δw: 0.133\n",
            "it: 60  | loss 3.39  | Δw: 0.105\n",
            "it: 70  | loss 3.15  | Δw: 0.094\n",
            "it: 80  | loss 2.91  | Δw: 0.085\n",
            "it: 90  | loss 2.68  | Δw: 0.077\n",
            "it: 100  | loss 2.44  | Δw: 0.071\n",
            "it: 110  | loss 2.22  | Δw: 0.066\n",
            "it: 120  | loss 2.0  | Δw: 0.059\n",
            "it: 130  | loss 1.79  | Δw: 0.054\n",
            "it: 140  | loss 1.59  | Δw: 0.049\n",
            "it: 150  | loss 1.41  | Δw: 0.045\n",
            "it: 160  | loss 1.24  | Δw: 0.04\n",
            "it: 170  | loss 1.09  | Δw: 0.036\n",
            "it: 180  | loss 0.96  | Δw: 0.033\n",
            "it: 190  | loss 0.84  | Δw: 0.03\n",
            "it: 200  | loss 0.74  | Δw: 0.027\n",
            "it: 210  | loss 0.65  | Δw: 0.024\n",
            "it: 220  | loss 0.58  | Δw: 0.022\n",
            "it: 230  | loss 0.51  | Δw: 0.02\n",
            "it: 240  | loss 0.46  | Δw: 0.018\n",
            "it: 250  | loss 0.42  | Δw: 0.016\n",
            "it: 260  | loss 0.38  | Δw: 0.015\n",
            "it: 270  | loss 0.34  | Δw: 0.014\n",
            "it: 280  | loss 0.32  | Δw: 0.012\n",
            "it: 290  | loss 0.29  | Δw: 0.012\n",
            "it: 300  | loss 0.27  | Δw: 0.011\n",
            "it: 310  | loss 0.25  | Δw: 0.01\n",
            "it: 320  | loss 0.23  | Δw: 0.009\n",
            "it: 330  | loss 0.22  | Δw: 0.009\n",
            "it: 340  | loss 0.21  | Δw: 0.008\n",
            "it: 350  | loss 0.2  | Δw: 0.008\n",
            "it: 360  | loss 0.19  | Δw: 0.008\n",
            "it: 370  | loss 0.18  | Δw: 0.007\n",
            "it: 380  | loss 0.17  | Δw: 0.007\n",
            "it: 390  | loss 0.16  | Δw: 0.006\n",
            "it: 400  | loss 0.15  | Δw: 0.006\n",
            "it: 410  | loss 0.15  | Δw: 0.006\n",
            "it: 420  | loss 0.14  | Δw: 0.006\n",
            "it: 430  | loss 0.14  | Δw: 0.005\n",
            "it: 440  | loss 0.13  | Δw: 0.005\n",
            "it: 450  | loss 0.13  | Δw: 0.005\n",
            "it: 460  | loss 0.12  | Δw: 0.005\n",
            "it: 470  | loss 0.12  | Δw: 0.005\n",
            "it: 480  | loss 0.12  | Δw: 0.005\n",
            "it: 490  | loss 0.11  | Δw: 0.004\n",
            "it: 500  | loss 0.11  | Δw: 0.004\n",
            "it: 510  | loss 0.11  | Δw: 0.004\n",
            "it: 520  | loss 0.1  | Δw: 0.004\n",
            "it: 530  | loss 0.1  | Δw: 0.004\n",
            "it: 540  | loss 0.1  | Δw: 0.004\n",
            "it: 550  | loss 0.1  | Δw: 0.004\n",
            "it: 560  | loss 0.09  | Δw: 0.004\n",
            "it: 570  | loss 0.09  | Δw: 0.003\n",
            "it: 580  | loss 0.09  | Δw: 0.003\n",
            "it: 590  | loss 0.09  | Δw: 0.003\n",
            "it: 600  | loss 0.09  | Δw: 0.003\n",
            "it: 610  | loss 0.08  | Δw: 0.003\n",
            "it: 620  | loss 0.08  | Δw: 0.003\n",
            "it: 630  | loss 0.08  | Δw: 0.003\n",
            "it: 640  | loss 0.08  | Δw: 0.003\n",
            "it: 650  | loss 0.08  | Δw: 0.003\n",
            "it: 660  | loss 0.08  | Δw: 0.003\n",
            "it: 670  | loss 0.07  | Δw: 0.003\n",
            "it: 680  | loss 0.07  | Δw: 0.003\n",
            "it: 690  | loss 0.07  | Δw: 0.003\n",
            "it: 700  | loss 0.07  | Δw: 0.003\n",
            "it: 710  | loss 0.07  | Δw: 0.003\n",
            "it: 720  | loss 0.07  | Δw: 0.003\n",
            "it: 730  | loss 0.07  | Δw: 0.003\n",
            "it: 740  | loss 0.07  | Δw: 0.002\n",
            "it: 750  | loss 0.06  | Δw: 0.002\n",
            "it: 760  | loss 0.06  | Δw: 0.002\n",
            "it: 770  | loss 0.06  | Δw: 0.002\n",
            "it: 780  | loss 0.06  | Δw: 0.002\n",
            "it: 790  | loss 0.06  | Δw: 0.002\n",
            "it: 800  | loss 0.06  | Δw: 0.002\n",
            "it: 810  | loss 0.06  | Δw: 0.002\n",
            "it: 820  | loss 0.06  | Δw: 0.002\n",
            "it: 830  | loss 0.06  | Δw: 0.002\n",
            "it: 840  | loss 0.06  | Δw: 0.002\n",
            "it: 850  | loss 0.06  | Δw: 0.002\n",
            "it: 860  | loss 0.05  | Δw: 0.002\n",
            "it: 870  | loss 0.05  | Δw: 0.002\n",
            "it: 880  | loss 0.05  | Δw: 0.002\n",
            "it: 890  | loss 0.05  | Δw: 0.002\n",
            "it: 900  | loss 0.05  | Δw: 0.002\n",
            "it: 910  | loss 0.05  | Δw: 0.002\n",
            "it: 920  | loss 0.05  | Δw: 0.002\n",
            "it: 930  | loss 0.05  | Δw: 0.002\n",
            "it: 940  | loss 0.05  | Δw: 0.002\n",
            "it: 950  | loss 0.05  | Δw: 0.002\n",
            "it: 960  | loss 0.05  | Δw: 0.002\n",
            "it: 970  | loss 0.05  | Δw: 0.002\n",
            "it: 980  | loss 0.05  | Δw: 0.002\n",
            "it: 990  | loss 0.05  | Δw: 0.002\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Train\n",
        "# =============================================================================\n",
        "print('training...')\n",
        "print_each = 10\n",
        "model.train()\n",
        "batch_iter = iter(data_loader)\n",
        "n_iteration = 1000\n",
        "for it in range(n_iteration):\n",
        "    \n",
        "    #get batch\n",
        "    batch, batch_iter = get_batch(data_loader, batch_iter)\n",
        "    \n",
        "    #infer\n",
        "    masked_input = batch['input']\n",
        "    masked_target = batch['target']\n",
        "    \n",
        "    masked_input = masked_input.cuda(non_blocking=True)\n",
        "    masked_target = masked_target.cuda(non_blocking=True)\n",
        "    output = model(masked_input)\n",
        "    \n",
        "    #compute the cross entropy loss \n",
        "    output_v = output.view(-1,output.shape[-1])\n",
        "    target_v = masked_target.view(-1,1).squeeze()\n",
        "    loss = loss_model(output_v, target_v)\n",
        "    \n",
        "    #compute gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    #apply gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    #print step\n",
        "    if it % print_each == 0:\n",
        "        print('it:', it, \n",
        "              ' | loss', np.round(loss.item(),2),\n",
        "              ' | Δw:', round(model.embeddings.weight.grad.abs().sum().item(),3))\n",
        "    \n",
        "    #reset gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of data from the validation set\n",
        "data = next(iter(val_loader))\n",
        "\n",
        "# Use the trained model to make predictions on the batch\n",
        "inputs = data['input'].cuda()\n",
        "outputs = model(inputs)\n",
        "\n",
        "# For each prediction, convert the indices back to words using the vocabulary dictionary\n",
        "vocab = dataset.vocab\n",
        "predictions = []\n",
        "\n",
        "# Check length of vocabulary\n",
        "print('Length of vocabulary:', len(vocab))\n",
        "\n",
        "# Check range of values in output tensor\n",
        "print('Min value in output tensor:', torch.min(outputs))\n",
        "print('Max value in output tensor:', torch.max(outputs))\n",
        "\n",
        "for i in range(len(outputs)):\n",
        "    output = outputs[i].argmax(dim=1).tolist()\n",
        "    prediction = [vocab.get(idx, '<unk>') for idx in output]\n",
        "    predictions.append(prediction)\n",
        "\n",
        "# Print the original sentence and the predicted sentence side by side for 10 examples\n",
        "for i in range(10):\n",
        "    input_sentence = ' '.join([vocab.get(idx, '<unk>') for idx in data['input'][i]])\n",
        "    output_sentence = ' '.join(predictions[i])\n",
        "    print('Input:    ', input_sentence)\n",
        "    print('Output:    ', output_sentence)\n",
        "   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "anfe5YpQuuZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "HtfaNU152Ajn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e54ec6cd-9b04-437d-9488-6d6d0873018d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving embeddings...\n",
            "end\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Results analysis\n",
        "# =============================================================================\n",
        "print('saving embeddings...')\n",
        "N = 3000\n",
        "np.savetxt('values.tsv', np.round(model.embeddings.weight.detach().cpu().numpy()[0:N], 2), delimiter='\\t', fmt='%1.2f')\n",
        "s = [dataset.rvocab[i] for i in range(N)]\n",
        "open('names.tsv', 'w+').write('\\n'.join(s) )\n",
        "\n",
        "\n",
        "print('end')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mv /content/vocab.txt /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "fY2T2h6A15pW"
      },
      "execution_count": 45,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "438fd45654d2411387c4fac2a79043ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b348965177324a4d917d26dc85e7cf9a",
              "IPY_MODEL_f66eff5d14d2497fa57975782bb3df1d",
              "IPY_MODEL_f1c3be14649b49b792d86cbb5352311e"
            ],
            "layout": "IPY_MODEL_d064cfcbf916409c8b9e1801fa0192b2"
          }
        },
        "b348965177324a4d917d26dc85e7cf9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6ae5681f7f94e249749e1453509aa15",
            "placeholder": "​",
            "style": "IPY_MODEL_f261d7f18d034d6195beee16cac8c070",
            "value": "100%"
          }
        },
        "f66eff5d14d2497fa57975782bb3df1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a73a27a57ad24c8f9fd9235ef871e96e",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbeb8c9114c44dc5b29b59cd7ab71082",
            "value": 3
          }
        },
        "f1c3be14649b49b792d86cbb5352311e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9b9780b6344296a49a2ebd2165f667",
            "placeholder": "​",
            "style": "IPY_MODEL_350bb42b3a634a8da41999c08e8306ef",
            "value": " 3/3 [00:00&lt;00:00, 106.50it/s]"
          }
        },
        "d064cfcbf916409c8b9e1801fa0192b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6ae5681f7f94e249749e1453509aa15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f261d7f18d034d6195beee16cac8c070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a73a27a57ad24c8f9fd9235ef871e96e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbeb8c9114c44dc5b29b59cd7ab71082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b9b9780b6344296a49a2ebd2165f667": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "350bb42b3a634a8da41999c08e8306ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}